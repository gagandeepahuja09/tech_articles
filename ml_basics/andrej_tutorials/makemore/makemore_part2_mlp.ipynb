{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With only keeping one character in the context, there were 27 possibilities.\n",
    "- If we start keeping context of more previous characters, the possibilities of context keep on increasing exponentially. (27 * 27 = 729), (27 * 27 * 27 = 20k) \n",
    "\n",
    "- [Paper link](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "- [makemore repo link](https://github.com/karpathy/makemore)\n",
    "\n",
    "- While we are focusing on a character level language model, the paper focuses on word level language model (17k words) but the model approach that we are going to use is going to be similar.\n",
    "\n",
    "- Take each word and associate let's say a 30 dimensional feature vector to each word.\n",
    "- Very crowded (a 30 dimensional feature vector), a lot of points for a very small space.\n",
    "- Every word is embedded to a 30 dimensional space.\n",
    "- Initially these words are spread out randomly.\n",
    "- Then we will tune the embeddings of these words using back propagation.\n",
    "- Words that are very similar to each other would be quite close to each other.\n",
    "- Example, when a neural network is trained on a lot of dataset, it could come to know that cats and dogs are used in a lot of similar context and are pets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplotlib.inline` not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib.inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        # log added to show the context and the the corresponding next character\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the embedding lookup table (C)\n",
    "- In the paper, they had 17k words which are embedded in a space as small as 30 dimensional space which gives 17k cross 30 matrix.\n",
    "- Since in our case, we are only dealing with characters and we have 27 possible characters, we will embed in an even smaller space of 2 dimensional space which gives 27 * 2 matrix.\n",
    "- C acts as our first layer to the neural network. They have no non-linearity (no tanh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.randn((27, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7382, 0.1996])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7382, 0.1996])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C[[5, 6, 7]] we can index for multi-dimensional vectors as well.\n",
    "# C[X] ==> X.shape is (32, 3). C[X].shape will (32, 3, 2) ==> a 2-dimension vector for each index.\n",
    "# first layer\n",
    "emb = C[X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the hidden layer\n",
    "* The number of inputs to the neuron of this layer is going to be 3 * 2. We have a 2-dimensional space for each character.\n",
    "* The no. of neurons is arbitrary, lets keep 100.\n",
    "* We will have tensors for weights and biases. Ideally the layer would just do: `emb@W1 + b1`\n",
    "* emb is 32, 3, 2 ==> got changed to 96, 2 and W1 is 6, 100. Hence cannot be multiplied.\n",
    "* Remember that we have 3 previous characters. emb[:, 0, :] will give embeds of the first character. (3rd previous)\n",
    "* We want to change 32, 3, 2 to 32, 6. We will concatenate across the dimension 1 instead of dimension 0.\n",
    "* We also used torch.unbind to generalize and not requiring to do emb[:, i, :] for all i. torch.unbind returns a tuple of all slices along a dimension, after removing it.\n",
    "* There is a much more efficient way to do this using torch.view.\n",
    "* torch.view helps us to convert a torch from one dimension to another efficiently.\n",
    "* This is efficient because internally, torch stores everything in a single dimension. We can check this via torch.storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW1\u001b[49m \u001b[38;5;241m+\u001b[39m b1\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)"
     ]
    }
   ],
   "source": [
    "emb @ W1 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([emb[:,0,:], emb[:, 1, :], emb[:, 2, :]], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 100]),\n",
       "  0.10918485373258591\n",
       "  -0.461626797914505\n",
       "  -0.5156719088554382\n",
       "  0.7642245888710022\n",
       "  -0.288330078125\n",
       "  0.05680552124977112\n",
       "  -1.0864781141281128\n",
       "  -1.0934231281280518\n",
       "  0.08613672107458115\n",
       "  1.3829567432403564\n",
       "  -1.1412547826766968\n",
       "  -0.236305370926857\n",
       "  0.12988881766796112\n",
       "  -0.6077059507369995\n",
       "  0.1187981441617012\n",
       "  -0.4598065912723541\n",
       "  0.665322482585907\n",
       "  -1.6671355962753296\n",
       "  -0.2006147801876068\n",
       "  -0.05465042218565941\n",
       "  1.861762285232544\n",
       "  -0.574219822883606\n",
       "  0.11379670351743698\n",
       "  0.23381808400154114\n",
       "  0.46911364793777466\n",
       "  -0.4386537969112396\n",
       "  0.7614145874977112\n",
       "  -0.8022424578666687\n",
       "  -0.40905603766441345\n",
       "  2.1134748458862305\n",
       "  0.0637543648481369\n",
       "  -0.30013832449913025\n",
       "  0.8704205751419067\n",
       "  -0.4817836880683899\n",
       "  -0.46995142102241516\n",
       "  0.021928006783127785\n",
       "  0.948181688785553\n",
       "  -0.5999742746353149\n",
       "  -0.35280749201774597\n",
       "  0.008993294090032578\n",
       "  -0.4769386053085327\n",
       "  0.2660994827747345\n",
       "  0.1439337581396103\n",
       "  -0.8809175491333008\n",
       "  -0.45529982447624207\n",
       "  -3.057620048522949\n",
       "  -0.2668952941894531\n",
       "  0.24039500951766968\n",
       "  -0.4166663587093353\n",
       "  1.4073917865753174\n",
       "  -1.2905763387680054\n",
       "  0.535383939743042\n",
       "  -0.5508918762207031\n",
       "  0.6665650606155396\n",
       "  -1.0008496046066284\n",
       "  0.10269749164581299\n",
       "  0.6590749025344849\n",
       "  0.0677623301744461\n",
       "  0.6635674834251404\n",
       "  0.7018306851387024\n",
       "  0.8676196932792664\n",
       "  0.21588212251663208\n",
       "  -0.8163983821868896\n",
       "  -0.8012824654579163\n",
       "  -0.034830547869205475\n",
       "  0.42653757333755493\n",
       "  0.9468604326248169\n",
       "  0.8063526749610901\n",
       "  0.8910760879516602\n",
       "  0.48595869541168213\n",
       "  1.469842553138733\n",
       "  0.9477961659431458\n",
       "  -0.5526735782623291\n",
       "  1.199765920639038\n",
       "  1.0649333000183105\n",
       "  0.9948601126670837\n",
       "  -0.49847865104675293\n",
       "  -0.6729153394699097\n",
       "  0.80174720287323\n",
       "  1.3148281574249268\n",
       "  -0.9278438091278076\n",
       "  1.2003353834152222\n",
       "  -1.5866190195083618\n",
       "  -0.3760375380516052\n",
       "  -0.559890866279602\n",
       "  -1.1437578201293945\n",
       "  -0.10770885646343231\n",
       "  0.7336757779121399\n",
       "  0.8170380592346191\n",
       "  1.2478710412979126\n",
       "  -1.7371762990951538\n",
       "  1.2250840663909912\n",
       "  -0.3635077476501465\n",
       "  0.5204224586486816\n",
       "  0.8775705695152283\n",
       "  -0.18064218759536743\n",
       "  0.7790393829345703\n",
       "  -1.615545392036438\n",
       "  0.7690803408622742\n",
       "  0.03588104248046875\n",
       "  1.7409999370574951\n",
       "  -0.6210510730743408\n",
       "  0.17658020555973053\n",
       "  -1.7141609191894531\n",
       "  0.5683360695838928\n",
       "  -0.4371787905693054\n",
       "  0.8102177977561951\n",
       "  -0.6062242984771729\n",
       "  0.11069891601800919\n",
       "  -0.40049993991851807\n",
       "  -2.224029541015625\n",
       "  0.8371714949607849\n",
       "  -0.5425592660903931\n",
       "  -1.3281025886535645\n",
       "  -0.5767349004745483\n",
       "  2.1845383644104004\n",
       "  0.9135735630989075\n",
       "  0.5068851113319397\n",
       "  0.2546035051345825\n",
       "  1.0026230812072754\n",
       "  0.2884712815284729\n",
       "  0.4754451513290405\n",
       "  0.3278403878211975\n",
       "  0.59662264585495\n",
       "  -0.40606486797332764\n",
       "  0.7008083462715149\n",
       "  1.0973551273345947\n",
       "  1.1398229598999023\n",
       "  0.3122383952140808\n",
       "  0.31497982144355774\n",
       "  1.0530264377593994\n",
       "  0.39164793491363525\n",
       "  1.874607801437378\n",
       "  0.04041007161140442\n",
       "  -0.6189053654670715\n",
       "  -0.07536567002534866\n",
       "  -2.473982334136963\n",
       "  -0.3866720199584961\n",
       "  2.382295846939087\n",
       "  0.6368448138237\n",
       "  0.25175783038139343\n",
       "  0.11882230639457703\n",
       "  -2.03525447845459\n",
       "  -1.0270582437515259\n",
       "  0.13904909789562225\n",
       "  1.6761021614074707\n",
       "  -0.07361970096826553\n",
       "  -0.4757857322692871\n",
       "  2.05973744392395\n",
       "  0.42214369773864746\n",
       "  -0.5560203194618225\n",
       "  0.07507224380970001\n",
       "  -0.3943002223968506\n",
       "  -0.808987557888031\n",
       "  -0.6777401566505432\n",
       "  1.2685223817825317\n",
       "  0.052308909595012665\n",
       "  -0.7342754006385803\n",
       "  1.0864062309265137\n",
       "  -0.6023966670036316\n",
       "  1.5387810468673706\n",
       "  -1.6436727046966553\n",
       "  -1.2785539627075195\n",
       "  -0.8766193985939026\n",
       "  0.9833944439888\n",
       "  0.14636243879795074\n",
       "  0.2004629224538803\n",
       "  -0.025835949927568436\n",
       "  1.751695990562439\n",
       "  -0.6452782154083252\n",
       "  0.11434514820575714\n",
       "  -0.5618692636489868\n",
       "  -1.3418891429901123\n",
       "  1.159658432006836\n",
       "  -0.7513241171836853\n",
       "  0.2711717486381531\n",
       "  -0.673636257648468\n",
       "  -1.0524935722351074\n",
       "  -0.43033549189567566\n",
       "  -1.1458226442337036\n",
       "  1.4495724439620972\n",
       "  0.6400493383407593\n",
       "  -0.8392534255981445\n",
       "  1.5148998498916626\n",
       "  0.5982629060745239\n",
       "  0.12307461351156235\n",
       "  1.307020664215088\n",
       "  -0.547218918800354\n",
       "  1.3495147228240967\n",
       "  -0.5680854916572571\n",
       "  -0.30956101417541504\n",
       "  0.34924033284187317\n",
       "  -2.369778871536255\n",
       "  1.4218580722808838\n",
       "  -0.6022410988807678\n",
       "  1.524080753326416\n",
       "  0.050937674939632416\n",
       "  -1.7009985446929932\n",
       "  0.3126167058944702\n",
       "  0.6078628301620483\n",
       "  -0.6008961200714111\n",
       "  0.7025710940361023\n",
       "  -0.7414896488189697\n",
       "  1.8591740131378174\n",
       "  -1.7346432209014893\n",
       "  -0.4417653977870941\n",
       "  -0.15164592862129211\n",
       "  -0.1640905737876892\n",
       "  -1.336745023727417\n",
       "  0.6994484066963196\n",
       "  0.36210376024246216\n",
       "  0.6116541624069214\n",
       "  -0.4187886118888855\n",
       "  -0.6770992279052734\n",
       "  0.41335177421569824\n",
       "  -0.7521163821220398\n",
       "  0.7858790159225464\n",
       "  -0.8596817255020142\n",
       "  0.9623168110847473\n",
       "  -1.5303664207458496\n",
       "  1.4237885475158691\n",
       "  0.8753494620323181\n",
       "  -2.5695388317108154\n",
       "  1.3583086729049683\n",
       "  -0.9709798097610474\n",
       "  0.573023796081543\n",
       "  -0.9670673608779907\n",
       "  -1.1879127025604248\n",
       "  0.028529753908514977\n",
       "  -1.3239609003067017\n",
       "  -0.6821058392524719\n",
       "  -0.3773098289966583\n",
       "  0.6762722730636597\n",
       "  -0.46004045009613037\n",
       "  -0.9016085863113403\n",
       "  1.3886022567749023\n",
       "  0.76054847240448\n",
       "  1.9313641786575317\n",
       "  -0.5818867683410645\n",
       "  -0.5136985778808594\n",
       "  0.8934035897254944\n",
       "  2.018897294998169\n",
       "  -0.7500408887863159\n",
       "  -0.7268354892730713\n",
       "  1.0807358026504517\n",
       "  -0.9648290872573853\n",
       "  0.007649097591638565\n",
       "  -0.9043102264404297\n",
       "  -2.002268075942993\n",
       "  -0.6248030066490173\n",
       "  -0.9782851934432983\n",
       "  -0.6308763027191162\n",
       "  2.257718563079834\n",
       "  1.5445265769958496\n",
       "  0.14164765179157257\n",
       "  -0.5151470899581909\n",
       "  -2.9719226360321045\n",
       "  -1.569535493850708\n",
       "  -0.6441669464111328\n",
       "  1.4075977802276611\n",
       "  0.2934035360813141\n",
       "  1.2190555334091187\n",
       "  1.0553781986236572\n",
       "  -0.08709464967250824\n",
       "  0.4533499479293823\n",
       "  0.005734601989388466\n",
       "  2.1203320026397705\n",
       "  -2.092996597290039\n",
       "  1.2745918035507202\n",
       "  -0.14506445825099945\n",
       "  -0.2360491305589676\n",
       "  -0.20806129276752472\n",
       "  1.9960837364196777\n",
       "  -1.7157400846481323\n",
       "  0.4409694969654083\n",
       "  -0.7167025208473206\n",
       "  -1.420345425605774\n",
       "  0.39032718539237976\n",
       "  1.1557502746582031\n",
       "  0.009727264754474163\n",
       "  0.49215734004974365\n",
       "  -0.558796763420105\n",
       "  0.2626248598098755\n",
       "  -0.6488820314407349\n",
       "  0.81087726354599\n",
       "  0.16369670629501343\n",
       "  0.316141813993454\n",
       "  0.135847806930542\n",
       "  -0.21844537556171417\n",
       "  -0.15597772598266602\n",
       "  -1.8870035409927368\n",
       "  0.1448381394147873\n",
       "  1.3541324138641357\n",
       "  1.2046277523040771\n",
       "  0.8501800894737244\n",
       "  -0.6254708170890808\n",
       "  0.3984833359718323\n",
       "  2.2864017486572266\n",
       "  -0.02780129387974739\n",
       "  -0.08287172764539719\n",
       "  -1.920965313911438\n",
       "  -1.3660790920257568\n",
       "  -2.1620118618011475\n",
       "  0.0782925933599472\n",
       "  -1.949467420578003\n",
       "  -0.21134456992149353\n",
       "  1.6611045598983765\n",
       "  0.28466328978538513\n",
       "  0.7669153809547424\n",
       "  0.6363027095794678\n",
       "  0.7519186735153198\n",
       "  -0.6812250018119812\n",
       "  -0.24562127888202667\n",
       "  0.09521225094795227\n",
       "  0.31047335267066956\n",
       "  -1.631386160850525\n",
       "  -2.399484157562256\n",
       "  0.14269781112670898\n",
       "  -0.08309560269117355\n",
       "  0.35935351252555847\n",
       "  0.647316038608551\n",
       "  -0.5310454964637756\n",
       "  -0.4889093339443207\n",
       "  0.40710726380348206\n",
       "  -1.4534846544265747\n",
       "  0.13548260927200317\n",
       "  0.7814634442329407\n",
       "  -0.07960250228643417\n",
       "  -0.7320512533187866\n",
       "  2.1077003479003906\n",
       "  -0.8309674263000488\n",
       "  1.4257351160049438\n",
       "  -0.35010650753974915\n",
       "  -0.14583078026771545\n",
       "  -0.32856640219688416\n",
       "  0.12142593413591385\n",
       "  1.4778449535369873\n",
       "  1.3644137382507324\n",
       "  1.5779646635055542\n",
       "  0.45114457607269287\n",
       "  -1.763877272605896\n",
       "  0.005393943749368191\n",
       "  2.129992723464966\n",
       "  -0.3939916491508484\n",
       "  -1.7290019989013672\n",
       "  -0.8286389708518982\n",
       "  -1.084505558013916\n",
       "  1.252123475074768\n",
       "  0.29970037937164307\n",
       "  0.008795572444796562\n",
       "  -1.186905860900879\n",
       "  1.241376280784607\n",
       "  1.4193601608276367\n",
       "  -0.7224504351615906\n",
       "  0.01122436486184597\n",
       "  1.5538949966430664\n",
       "  -0.0355769544839859\n",
       "  -1.6973367929458618\n",
       "  1.3204686641693115\n",
       "  0.16652731597423553\n",
       "  0.2939871847629547\n",
       "  -0.13824427127838135\n",
       "  0.884131669998169\n",
       "  -0.17169465124607086\n",
       "  1.8756972551345825\n",
       "  -0.5089204907417297\n",
       "  -0.6745669841766357\n",
       "  -0.5655027627944946\n",
       "  -0.7157319188117981\n",
       "  -0.19949506223201752\n",
       "  0.4236651659011841\n",
       "  0.7947254180908203\n",
       "  -0.5170738101005554\n",
       "  -0.07493945956230164\n",
       "  2.214468240737915\n",
       "  -1.2075071334838867\n",
       "  -0.17604370415210724\n",
       "  -0.5515730977058411\n",
       "  -0.2534468173980713\n",
       "  -0.29320773482322693\n",
       "  -0.7408337593078613\n",
       "  -0.13167442381381989\n",
       "  0.3067024350166321\n",
       "  -1.2198588848114014\n",
       "  0.7374594807624817\n",
       "  -1.5169419050216675\n",
       "  -1.0231767892837524\n",
       "  -1.337490200996399\n",
       "  1.358095645904541\n",
       "  0.5816460847854614\n",
       "  -1.803133487701416\n",
       "  -2.177320718765259\n",
       "  0.8032631874084473\n",
       "  -0.4200107157230377\n",
       "  -0.8456874489784241\n",
       "  -0.41170477867126465\n",
       "  1.2428171634674072\n",
       "  1.6744441986083984\n",
       "  0.15539206564426422\n",
       "  -0.4769725203514099\n",
       "  -1.879551887512207\n",
       "  0.518064022064209\n",
       "  -0.5673779845237732\n",
       "  1.151496410369873\n",
       "  -0.1863936483860016\n",
       "  0.3693940341472626\n",
       "  1.2969757318496704\n",
       "  -0.1355997771024704\n",
       "  0.045936811715364456\n",
       "  -0.23974408209323883\n",
       "  3.131984233856201\n",
       "  -0.4501745104789734\n",
       "  0.4647945761680603\n",
       "  1.138229250907898\n",
       "  -0.3011949360370636\n",
       "  0.0049299513921141624\n",
       "  1.3543776273727417\n",
       "  -1.0743253231048584\n",
       "  0.7689617276191711\n",
       "  -0.14608699083328247\n",
       "  -0.13768908381462097\n",
       "  -0.007150748744606972\n",
       "  0.5404199957847595\n",
       "  0.19002807140350342\n",
       "  1.8844488859176636\n",
       "  -0.47786790132522583\n",
       "  0.3424566388130188\n",
       "  0.8203292489051819\n",
       "  -0.5555393099784851\n",
       "  0.49920138716697693\n",
       "  1.4263272285461426\n",
       "  -0.6198888421058655\n",
       "  -0.3636303246021271\n",
       "  0.18234087526798248\n",
       "  -0.6455953121185303\n",
       "  -1.7583478689193726\n",
       "  0.7904767990112305\n",
       "  0.862365186214447\n",
       "  -1.5396302938461304\n",
       "  0.383142352104187\n",
       "  -0.4607084095478058\n",
       "  -0.4606499671936035\n",
       "  1.6059460639953613\n",
       "  0.616435170173645\n",
       "  -0.7434466481208801\n",
       "  -1.0561507940292358\n",
       "  -0.28860267996788025\n",
       "  -0.8490796089172363\n",
       "  0.19042998552322388\n",
       "  -0.17053064703941345\n",
       "  2.0466256141662598\n",
       "  0.6640304327011108\n",
       "  0.7843581438064575\n",
       "  -0.8786290884017944\n",
       "  -0.06624437123537064\n",
       "  -0.8418855667114258\n",
       "  -1.3787015676498413\n",
       "  0.1370958536863327\n",
       "  1.1517702341079712\n",
       "  -0.6167230606079102\n",
       "  0.7292369604110718\n",
       "  -0.21424414217472076\n",
       "  0.10239063948392868\n",
       "  -0.1837533563375473\n",
       "  -0.3059385418891907\n",
       "  -0.7235109806060791\n",
       "  1.2209608554840088\n",
       "  -1.027321696281433\n",
       "  -1.3806084394454956\n",
       "  -0.18853779137134552\n",
       "  -0.10543636232614517\n",
       "  0.6316551566123962\n",
       "  -0.6371744275093079\n",
       "  2.579705238342285\n",
       "  -1.055378794670105\n",
       "  0.4474973976612091\n",
       "  -0.17534837126731873\n",
       "  1.1151020526885986\n",
       "  -0.23392169177532196\n",
       "  -0.5700474381446838\n",
       "  -0.41066935658454895\n",
       "  2.089604377746582\n",
       "  -0.9846164584159851\n",
       "  -0.5635431408882141\n",
       "  0.2384224832057953\n",
       "  -0.013860889710485935\n",
       "  1.5094703435897827\n",
       "  -0.0818503201007843\n",
       "  -0.07835759967565536\n",
       "  0.5840871334075928\n",
       "  -0.6792887449264526\n",
       "  -0.6464976668357849\n",
       "  -0.2141369879245758\n",
       "  2.928534984588623\n",
       "  0.7772015333175659\n",
       "  0.6580137610435486\n",
       "  -0.4720298945903778\n",
       "  -0.04837241768836975\n",
       "  0.9450778365135193\n",
       "  0.17401382327079773\n",
       "  0.8739393353462219\n",
       "  -1.5016313791275024\n",
       "  -1.7354403734207153\n",
       "  -0.47905978560447693\n",
       "  -1.692463755607605\n",
       "  -0.3858720362186432\n",
       "  -0.05737414211034775\n",
       "  0.4594055712223053\n",
       "  -1.5451641082763672\n",
       "  -1.2435017824172974\n",
       "  1.6928555965423584\n",
       "  -0.4529799222946167\n",
       "  2.337026834487915\n",
       "  2.3194515705108643\n",
       "  1.5108734369277954\n",
       "  -0.1621113121509552\n",
       "  -1.644667148590088\n",
       "  -1.2611548900604248\n",
       "  -2.332620143890381\n",
       "  1.7190123796463013\n",
       "  -0.598153293132782\n",
       "  0.36929452419281006\n",
       "  -0.14288842678070068\n",
       "  1.7853083610534668\n",
       "  -0.8490452766418457\n",
       "  -0.16459189355373383\n",
       "  -1.1456553936004639\n",
       "  -1.3314558267593384\n",
       "  -0.0403461717069149\n",
       "  -0.06515533477067947\n",
       "  0.4220406115055084\n",
       "  0.08039836585521698\n",
       "  -1.1072216033935547\n",
       "  1.2665146589279175\n",
       "  1.5118768215179443\n",
       "  0.23087181150913239\n",
       "  -0.20117388665676117\n",
       "  -0.6443080306053162\n",
       "  0.6753838062286377\n",
       "  -0.2468944787979126\n",
       "  0.1456700563430786\n",
       "  -1.3130959272384644\n",
       "  -0.9538310170173645\n",
       "  1.760392189025879\n",
       "  -0.9054014682769775\n",
       "  0.38114747405052185\n",
       "  1.076724886894226\n",
       "  0.8373882174491882\n",
       "  -1.3299446105957031\n",
       "  0.48947298526763916\n",
       "  0.7150253653526306\n",
       "  0.9576482176780701\n",
       "  -0.27978289127349854\n",
       "  -1.2809487581253052\n",
       "  -0.4110974371433258\n",
       "  0.45395299792289734\n",
       "  -0.5162392258644104\n",
       "  0.6264733672142029\n",
       "  0.49256420135498047\n",
       "  -0.09869823604822159\n",
       "  -0.5934067368507385\n",
       "  0.7772834300994873\n",
       "  1.8326550722122192\n",
       "  1.3130121231079102\n",
       "  1.1284966468811035\n",
       "  0.9727650880813599\n",
       "  1.0102890729904175\n",
       "  -1.0037428140640259\n",
       "  -0.6210194826126099\n",
       "  0.15530620515346527\n",
       "  0.8401294946670532\n",
       "  -1.030773639678955\n",
       "  -1.487991452217102\n",
       "  -0.8256737589836121\n",
       "  0.08908091485500336\n",
       "  -0.22831857204437256\n",
       "  -1.2586405277252197\n",
       "  -0.6193172335624695\n",
       "  -1.6323363780975342\n",
       "  1.4734511375427246\n",
       "  0.56241774559021\n",
       "  1.2680134773254395\n",
       "  0.13753540813922882\n",
       "  -0.3561069369316101\n",
       "  -0.054704878479242325\n",
       "  -2.0873007774353027\n",
       "  0.014722959138453007\n",
       "  0.11973085254430771\n",
       "  -0.3123790919780731\n",
       "  1.4945300817489624\n",
       "  -0.5538240075111389\n",
       "  -0.6924221515655518\n",
       "  -1.2663824558258057\n",
       "  -0.15175926685333252\n",
       "  -0.6183609962463379\n",
       "  -0.36405062675476074\n",
       "  0.5618543028831482\n",
       "  0.7203018069267273\n",
       "  1.4573146104812622\n",
       "  -1.6058624982833862\n",
       " [torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 600])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.storage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

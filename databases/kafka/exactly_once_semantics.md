**What is exactly once semantics in Kafka?**
* Tailored to stream processing and not message delivering. It is key that we make this distinction.
* Exactly-once delivery is different from exactly-once semantics. By exactly-once delivery, we want to ensure that a message is not delivered to a consumer more than once. Idempotency is very important for critical flows like financial transactions.
* EOS is designed with Kafka streams in mind. Read the data from the topic, process the data and write the results back.
    * Hence we need to ensure that the message in processed exactly onces and result is published exactly once.
    * We can retry if there is an error but the result is the same as if no error would have happened.
* Low-level Kafka APIs are used for implementing Kafka streams. Deep-down there are a lot of wire-protocol details also.

**Why is exactly once delivery / semantics a hard problem?**
* How does a producer come to know that the message has been stored by the Kafka cluster? 
* This is via acknowledgment. What if the message is stored but the acknowledgement fails either due to network failure or timeout (network delay).
* If we need to retry something, then we need to make it idempotent.

**Idempotent Producer**
* If Kafka EOS, there is a feature called Idempotent Producer. This is just a config change on the producer and not different APIs.
* We assign a unique id to each message sent by the producer. 
    * Question: why not use offsets?

**How do we handle producer failures?**

**How is the unique id generated?**
* An auto increment id won't be enough as it could lead to the same id generated by 2 producers. Hence a producer id needs to be generated by the broker.

**Why do we need topic in Kafka?**

**Transactions in Kafka**
* In Kafka, transaction would be defined as a multi-topic, multi-partition atomic write.
* It means that we can send multiple messages to different topics and partitions and either all of those writes would be visible or none of those of writes.
* As a user (application id), we need to assign a "transaction_id" which is unique for the *whole cluster*.
* At the broker side, we have an additional component called *Transaction Coordinator* (inside the broker).
    * It is similar to the consumer group coordinator (group membership).
    * Transaction coordinator tracks the status of the transactions and what partitions and topics are involved in the transaction. 